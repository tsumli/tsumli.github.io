<!DOCTYPE html>
<html lang="ja">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <title>Video Swin Transformer を読む | tsumli-pages</title>

  <meta charset="UTF-8">
  <meta name="language" content="en">
  <meta name="description" content="">
  <meta name="keywords" content="transformer">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  
  

  <link rel="shortcut icon" type="image/png" href="http://localhost:1313/favicon.ico" />


  
  
    
 
  
  
  
  
  
  
    
    <link type="text/css" rel="stylesheet" href="http://localhost:1313/css/post.min.56c8810b0f07bc4b6fe3dd802a8194d08a2ed5a4903bdf2a4859c17f3860a7e7.css" integrity="sha256-VsiBCw8HvEtv492AKoGU0Iou1aSQO98qSFnBfzhgp&#43;c="/>
  
    
    <link type="text/css" rel="stylesheet" href="http://localhost:1313/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css" integrity="sha256-47DEQpj8HBSa&#43;/TImW&#43;5JCeuQeRkm5NMpJWZG3hSuFU="/>
  
  
   
   
    

<script type="application/ld+json">
  
    {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/localhost:1313\/"
      },
      "articleSection" : "blog",
      "name" : "Video Swin Transformer を読む",
      "headline" : "Video Swin Transformer を読む",
      "description" : "",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2021",
      "datePublished": "2021-10-14 15:55:54 \u002b0000 UTC",
      "dateModified" : "2021-10-14 15:55:54 \u002b0000 UTC",
      "url" : "http:\/\/localhost:1313\/blog\/paper\/video-swin-transformer\/",
      "wordCount" : "1585",
      "keywords" : ["transformer", "Blog"]
    }
  
  </script>

</head>

<body>
  <div class="burger__container">
  <div class="burger" aria-controls="navigation" aria-label="Menu">
    <div class="burger__meat burger__meat--1"></div>
    <div class="burger__meat burger__meat--2"></div>
    <div class="burger__meat burger__meat--3"></div>
  </div>
</div>
 

  <nav class="nav" id="navigation">
  <ul class="nav__list">
    
    
      <li>
        <a  href="http://localhost:1313/">about</a>
      </li>
    
      <li>
        <a  class="active"
         href="http://localhost:1313/blog">blog</a>
      </li>
    
  </ul>
</nav>


  <main>
    
    

    <div class="flex-wrapper">
      <div class="post__container">
        <div class="post">
          <header class="post__header">
            <h1 id="post__title">Video Swin Transformer を読む</h1>
            <time datetime="2021-10-14 15:55:54 &#43;0000 UTC" class="post__date">Oct 14 2021</time> 
            <link rel="stylesheet" href="http://localhost:1313//css/lightbox.min.css">
            <script type="text/javascript">
 MathJax = {
   tex: {
     inlineMath: [['$','$'], ['\\(','\\)']],
     processEscapes: true,
     tags: "ams",
     autoload: {
       color: [],
       colorV2: ['color']
     },
     packages: {'[+]': ['noerrors']}
   },
   chtml: {
     matchFontHeight: false,
     displayAlign: "left", 
     displayIndent: "2em"
   },
   options: {
     skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
     renderActions: {
        
       find_script_mathtex: [10, function (doc) {
         for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
           const display = !!node.type.match(/; *mode=display/);
           const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
           const text = document.createTextNode('');
           node.parentNode.replaceChild(text, node);
           math.start = {node: text, delim: '', n: 0};
           math.end = {node: text, delim: '', n: 0};
           doc.math.push(math);
         }
       }, '']
     }
   },
   loader: {
     load: ['[tex]/noerrors']
   }
 };
</script>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script"></script>

<link rel="stylesheet" type="text/css" href="http://localhost:1313/css/mathjax-style.css">

          </header>
          <article class="post__content">
              
<p><a href="https://arxiv.org/abs/2106.13230" 
  
   target="_blank" rel="noreferrer noopener" 
><strong>Video Swin Transformer</strong></a>
という論文を読んでいきます (本文中の図は論文より引用) 。ざっくり言うと、Swin Transformerをそのままvideoの入力に拡張した論文です。</p>
<h2 id="method">Method<a class="anchor" href="#method">#</a></h2>
<p>図1に全体のアーキテクチャを示す (Swin-Tという提案モデルの中でも小さなvariantの図) 。
全体の処理の流れはSwin Transformerとほぼ同じになるように設計されている。
<br>
<br></p>

  





<figure
  
  
  
  style='margin:0 auto;text-align:center;'
  >
    <a 
      
        data-lightbox="image-images/arch.png"
      
      
        href="http://localhost:1313/blog/paper/video-swin-transformer/images/arch.png"
      
    
    >
  <img
      
        src="http://localhost:1313/blog/paper/video-swin-transformer/images/arch.png"
      
        alt="Overall architecture (Swin-T)."
        
        
         />
    </a>
  
  
    <figcaption>
      <span class="img--caption">
        Figure . Overall architecture (Swin-T).
        
      </span>
    </figcaption>
  
</figure>




<p>input videoは $T \text{ (frame)} \times H \times W \times 3$ のサイズを持つとする。
Video Swin Transformerでは、$2\times 4 \times 4 \times 3 = 96$次元の3D patch をひとつのtokenとして扱う。つまり、全部で $\frac{T}{2} \times \frac{H}{4} \times \frac{W}{4}$ のtokenを持つ。
その後、線形層を用いて任意の次元 ($C$とする) に拡張することができる。</p>
<p>各stageにおいて、時間方向にはdown-sampleを行わず、空間方向にdown-sampleを行う。また、各tokenの持つ特徴量は2倍に増加していく。</p>
<p>アーキテクチャの核を成すのがVideo Swin Transformer Blockである (図1) 。
標準のTransformerのmultihead self-attention (MSA) の部分を3D shifted windowに基づいたMSAに置き換えることで作られる。図の&quot;3D W-MSA&quot;は通常のwindowのMSA、&ldquo;3D SW-MSA&quot;はshifted windowのMSAを表す。</p>

  





<figure
  
  
  
  style='margin:0 auto;text-align:center;'
  >
    <a 
      
        data-lightbox="image-images/vst-block.png"
      
      
        href="http://localhost:1313/blog/paper/video-swin-transformer/images/vst-block.png"
      
    
    >
  <img
      
        src="http://localhost:1313/blog/paper/video-swin-transformer/images/vst-block.png"
      
        alt="Vision Swin Transformer Block."
        
        
         />
    </a>
  
  
    <figcaption>
      <span class="img--caption">
        Figure 1. Vision Swin Transformer Block.
        
      </span>
    </figcaption>
  
</figure>




<h3 id="3d-shifted-window-based-msa-module">3D Shifted Window based MSA Module<a class="anchor" href="#3d-shifted-window-based-msa-module">#</a></h3>
<p>画像の場合と比べて、動画は時間軸を考えないといけないため、動画を扱うときには入力tokenがとても多くなる。
そのため、global self-attentionは計算量やメモリのコスト的に適していない。そこで、Swin Transformerのself-attentionモジュールにlocality inductive biasを導入したモデルを考える。</p>
<h4 id="multi-head-self-attention-on-non-overlapping-3d-windows">Multi-head self-attention on non-overlapping 3D windows</h4>
<p>画像認識に用いられるようなMSAをvideoに対応するように拡張する。
$T&rsquo; \times W&rsquo; \times W&rsquo;$ の3D tokenからなるvideoと $P\times M \times M$ の3D windowがあるとき、
つまり、input tokenは $\lceil \frac{T&rsquo;}{P} \rceil \times \lceil \frac{H&rsquo;}{M} \rceil \times \lceil \frac{W}{M} \rceil$ 個の重複しない3D windowに分割される。</p>
<br>

  





<figure
  
  
  
  style='margin:0 auto;text-align:center;'
  >
    <a 
      
        data-lightbox="image-images/shift-window.png"
      
      
        href="http://localhost:1313/blog/paper/video-swin-transformer/images/shift-window.png"
      
    
    >
  <img
      
        src="http://localhost:1313/blog/paper/video-swin-transformer/images/shift-window.png"
      
        alt="An illustrated wxample of 3D shifted windows."
        
        
         />
    </a>
  
  
    <figcaption>
      <span class="img--caption">
        Figure 2. An illustrated wxample of 3D shifted windows.
        
      </span>
    </figcaption>
  
</figure>




<p>例を図2に示す。input sizeが $8 \times 8 \times 8$ で、window sizeが $4 \times 4\times 4$ のとき、層 $l$ では通常の分割法、層 $l+1$ ではwindowが $(\frac{P}{2}, \frac{M}{2}, \frac{M}{2}) = (2, 2, 2)$ tokenだけシフトする。このようにするとwindowの数が増えてしまう ($3 \times 3 \times 3 = 27$ になる) が、Swin Transformerと同様に処理することで8個のままになる。</p>
<p>このshifted windowを用いてVideo Swin Transformer blockでは次のように計算が行われる (Swin Transformerと同様)</p>
<p>\begin{align*}
\hat{\mathbf{z}}^l &amp;= \text{3DW-MSA} (\mathrm{LN}(\mathbf{z}^{l-1})) + \mathbf{z}^{PyTurboJPEGl-1}, \\
\mathbf{z}^l &amp;= \mathrm{FFN} (\mathrm{LN}(\hat{\mathbf{z}}^{l})) + \hat{\mathbf{z}}^{l}, \\
\hat{\mathbf{z}}^{l+1} &amp;= \text{3DSW-MSA} (\mathrm{LN}(\mathbf{z}^{l})) + \mathbf{z}^{l}, \\
\mathbf{z}^{l+1} &amp;= \mathrm{FFN} (\mathrm{LN}(\hat{\mathbf{z}}^{l+1})) + \hat{\mathbf{z}}^{l+1},
\end{align*}</p>
<h4 id="3d-relative-position-bias">3D Relative Position Bias</h4>
<p>3Dの相対的なbias $B \in \mathbb{R}^{P^2 \times M^2 \times M^2}$ をAttentionの計算時に加える。
\begin{align*}
\text{Attention}(Q, K, V) = \text{SoftMax}(QK^\mathsf{T} / \sqrt{d} + B) V
\end{align*}</p>
<p>相対的な位置は時間方向に $[P + 1, P - 1]$、高さ・幅方向に $[-M + 1, M - 1]$ の中に収まることを利用し、biasを $\hat{B} \in \mathbb{R}^{(2P-1) \times (2M - 1) \times (2M-1)}$ のようにパラメータ化できる。</p>
<h3 id="architecture-variants">Architecture Variants<a class="anchor" href="#architecture-variants">#</a></h3>
<p>サイズと計算量のことなる複数のモデルを作ることができる。</p>
<ul>
<li>Swin-T: $C=96$, layer numbers = {2, 2, 6, 2}</li>
<li>Swin-S: $C=96$, layer numbers = {2, 2, 18, 2}</li>
<li>Swin-B: $C=128$, layer numbers = {2, 2, 18, 2}</li>
<li>Swin-L: $C=192$, layer numbers = {2, 2, 18, 2}</li>
</ul>
<h2 id="result">Result<a class="anchor" href="#result">#</a></h2>
<p><br>

  





<figure
  
  
  
  style='margin:0 auto;text-align:center;'
  >
    <a 
      
        data-lightbox="image-images/result.png"
      
      
        href="http://localhost:1313/blog/paper/video-swin-transformer/images/result.png"
      
    
    >
  <img
      
        src="http://localhost:1313/blog/paper/video-swin-transformer/images/result.png"
      
        alt="Vision Swin Transformer Block."
        
        
         />
    </a>
  
  
    <figcaption>
      <span class="img--caption">
        Figure 3. Vision Swin Transformer Block.
        
      </span>
    </figcaption>
  
</figure>



</p>
<p>Kinetics-400に対して実験を行った結果、ImageNet-1Kで事前学習を行ったSwin-Sが MViT-B比べて計算量は同様であるものの、良い結果 (小さくはあるが) を残している。また、ConvNet X3D-XXLと比べるとかなり良い結果を残している。ほかのモデル (variants) も計算量を削減しつつ比較手法に対して良い結果を出している。</p>
<p>他に、Kinetics-600とSomething-Something v2での実験、ablation studyが行われている。</p>
<h2 id="references">References<a class="anchor" href="#references">#</a></h2>
<ul>
<li>
<p>Video Swin Transformer implementation <a href="https://github.com/SwinTransformer/Video-Swin-Transformer" 
  
   target="_blank" rel="noreferrer noopener" 
><img src="https://gh-card.dev/repos/SwinTransformer/Video-Swin-Transformer.svg" alt="SwinTransformer/Video-Swin-Transformer - GitHub"></a>
</p>
</li>
<li>
<p><a href="http://localhost:1313/blog/paper/swin-transformer/" 
  
  
>Swin Transformerのpost</a>
</p>
</li>
</ul>


              
                  

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>
              
          </article>
          

<ul class="tags__list">
    
    <li class="tag__item">
        <a class="tag__link" href="http://localhost:1313/tags/transformer/">transformer</a>
    </li>
    <li class="tag__item">
        <a class="tag__link" href="http://localhost:1313/tags/paper/">paper</a>
    </li></ul>

 <div class="pagination">
  
    <a class="pagination__item" href="http://localhost:1313/blog/paper/swin-transformer/">
        <span class="pagination__label">Previous Post</span>
        <span class="pagination__title">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows を読む</span>
    </a>
  

  
    <a class="pagination__item" href="http://localhost:1313/blog/paper/fomm/">
      <span class="pagination__label">Next Post</span>
      <span class="pagination__title" >First Order Motion Model for Image Animation (FOMM) を読む</span>
    </a>
  
</div>

          
          <footer class="post__footer">
            


<div class="social-icons">
  
     
    
      <a class="social-icons__link" rel="me" title="Kaggle"
         href="https://www.kaggle.com/tsumli"
         target="_blank" rel="noopener">
        <div class="social-icons__icon" style="background-image: url('http://localhost:1313/svg/kaggle.svg')"></div>
      </a>
    
  
     
    
      <a class="social-icons__link" rel="me" title="GitHub"
         href="https://github.com/tsumli"
         target="_blank" rel="noopener">
        <div class="social-icons__icon" style="background-image: url('http://localhost:1313/svg/github.svg')"></div>
      </a>
    
     
</div>

            <p>© 2025</p>
            <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
            <link rel="stylesheet" href="http://localhost:1313//css/lightbox.min.css">
            <script src="http://localhost:1313//js/lightbox.min.js"></script>
          </footer>
          </div>
      </div>
      
      <div class="toc-container">
           <div class="toc-post-title">Video Swin Transformer を読む</div> 
        <nav id="TableOfContents">
  <ul>
    <li><a href="#method">Method</a>
      <ul>
        <li><a href="#3d-shifted-window-based-msa-module">3D Shifted Window based MSA Module</a></li>
        <li><a href="#architecture-variants">Architecture Variants</a></li>
      </ul>
    </li>
    <li><a href="#result">Result</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
      </div>
      
    </div>
    

  </main>

   

  
  <script src="http://localhost:1313/js/index.min.301a8b0870381bf76b3b5182e8966d363a0474281183439beb024d8b8228fc66.js" integrity="sha256-MBqLCHA4G/drO1GC6JZtNjoEdCgRg0Ob6wJNi4Io/GY=" crossorigin="anonymous"></script>
  
  
  <script src="https://unpkg.com/prismjs@1.20.0/components/prism-core.min.js"></script>

  
  <script src="https://unpkg.com/prismjs@1.20.0/plugins/autoloader/prism-autoloader.min.js"
    data-autoloader-path="https://unpkg.com/prismjs@1.20.0/components/"></script>

  
    <script src="http://localhost:1313/js/table-of-contents.js"></script>
  


</body>

</html>
