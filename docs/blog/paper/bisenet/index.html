<!DOCTYPE html>
<html lang="ja">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <title>BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation を読む | tsumli-pages</title>

  <meta charset="UTF-8">
  <meta name="language" content="en">
  <meta name="description" content="">
  <meta name="keywords" content="BiSeNet , segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  
  

  <link rel="shortcut icon" type="image/png" href="http://localhost:1313/favicon.ico" />


  
  
    
 
  
  
  
  
  
  
    
    <link type="text/css" rel="stylesheet" href="http://localhost:1313/css/post.min.56c8810b0f07bc4b6fe3dd802a8194d08a2ed5a4903bdf2a4859c17f3860a7e7.css" integrity="sha256-VsiBCw8HvEtv492AKoGU0Iou1aSQO98qSFnBfzhgp&#43;c="/>
  
    
    <link type="text/css" rel="stylesheet" href="http://localhost:1313/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css" integrity="sha256-47DEQpj8HBSa&#43;/TImW&#43;5JCeuQeRkm5NMpJWZG3hSuFU="/>
  
  
   
   
    

<script type="application/ld+json">
  
    {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/localhost:1313\/"
      },
      "articleSection" : "blog",
      "name" : "BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation を読む",
      "headline" : "BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation を読む",
      "description" : "",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2022",
      "datePublished": "2022-09-06 10:33:39 \u002b0000 UTC",
      "dateModified" : "2022-09-06 10:33:39 \u002b0000 UTC",
      "url" : "http:\/\/localhost:1313\/blog\/paper\/bisenet\/",
      "wordCount" : "1254",
      "keywords" : ["BiSeNet", "segmentation", "Blog"]
    }
  
  </script>

</head>

<body>
  <div class="burger__container">
  <div class="burger" aria-controls="navigation" aria-label="Menu">
    <div class="burger__meat burger__meat--1"></div>
    <div class="burger__meat burger__meat--2"></div>
    <div class="burger__meat burger__meat--3"></div>
  </div>
</div>
 

  <nav class="nav" id="navigation">
  <ul class="nav__list">
    
    
      <li>
        <a  href="http://localhost:1313/">about</a>
      </li>
    
      <li>
        <a  class="active"
         href="http://localhost:1313/blog">blog</a>
      </li>
    
  </ul>
</nav>


  <main>
    
    

    <div class="flex-wrapper">
      <div class="post__container">
        <div class="post">
          <header class="post__header">
            <h1 id="post__title">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation を読む</h1>
            <time datetime="2022-09-06 10:33:39 &#43;0000 UTC" class="post__date">Sep 6 2022</time> 
            <link rel="stylesheet" href="http://localhost:1313//css/lightbox.min.css">
            <script type="text/javascript">
 MathJax = {
   tex: {
     inlineMath: [['$','$'], ['\\(','\\)']],
     processEscapes: true,
     tags: "ams",
     autoload: {
       color: [],
       colorV2: ['color']
     },
     packages: {'[+]': ['noerrors']}
   },
   chtml: {
     matchFontHeight: false,
     displayAlign: "left", 
     displayIndent: "2em"
   },
   options: {
     skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
     renderActions: {
        
       find_script_mathtex: [10, function (doc) {
         for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
           const display = !!node.type.match(/; *mode=display/);
           const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
           const text = document.createTextNode('');
           node.parentNode.replaceChild(text, node);
           math.start = {node: text, delim: '', n: 0};
           math.end = {node: text, delim: '', n: 0};
           doc.math.push(math);
         }
       }, '']
     }
   },
   loader: {
     load: ['[tex]/noerrors']
   }
 };
</script>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script"></script>

<link rel="stylesheet" type="text/css" href="http://localhost:1313/css/mathjax-style.css">

          </header>
          <article class="post__content">
              
<p><a href="https://arxiv.org/abs/1808.00897" 
  
   target="_blank" rel="noreferrer noopener" 
><strong>BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</strong></a>
<br>
[Yu et al. ECCV 2018] という論文を読んでいきます。 (本文中の図は論文より引用) 。
semantic segmentationの課題である、リアルタイム性 (推論速度) と精度のトレードオフ
を解決する新たなネットワークBilateral Segmentation Network (BiSeNet) の提案。</p>
<h2 id="introduction">Introduction<a class="anchor" href="#introduction">#</a></h2>
<p>segmentationを高速化する手法は3つのアプローチに分かれる。(下図 (a) 参照)</p>
<ol>
<li>入力サイズを制限する &hellip; 品質や精度の低下</li>
<li>Pruning (枝刈り) を行う &hellip; 大きなサイズに対応できない</li>
<li>Spatial Dropoutを適用する (Ref: <a href="https://arxiv.org/abs/1606.02147" 
  
   target="_blank" rel="noreferrer noopener" 
>ENet</a>
) &hellip; 物を区別する能力の低下</li>
</ol>
<p>また、一般的にU-shapeのネットワークが使われるが、2つの弱点がある。</p>
<ol>
<li>高い解像度の特徴量マップの計算コストが過剰であり、スピードが低下する</li>
<li>PruningやCroppingによって失われてしまった情報は、浅い層のNNで得ることができない (下図 (b))</li>
</ol>

  





<figure
  
  
  
  style='margin:0 auto;text-align:center;'
  >
    <a 
      
        data-lightbox="image-images/arch.png"
      
      
        href="http://localhost:1313/blog/paper/bisenet/images/arch.png"
      
    
    >
  <img
      
        src="http://localhost:1313/blog/paper/bisenet/images/arch.png"
      
        alt="Illustlation of the architectures to speed up and our proposed approach."
        
        
         />
    </a>
  
  
    <figcaption>
      <span class="img--caption">
        Figure . Illustlation of the architectures to speed up and our proposed approach.
        
      </span>
    </figcaption>
  
</figure>




<h2 id="method">Method<a class="anchor" href="#method">#</a></h2>

  





<figure
  
  
  
  style='margin:0 auto;text-align:center;'
  >
    <a 
      
        data-lightbox="image-images/bisenet.png"
      
      
        href="http://localhost:1313/blog/paper/bisenet/images/bisenet.png"
      
    
    >
  <img
      
        src="http://localhost:1313/blog/paper/bisenet/images/bisenet.png"
      
        alt="An overview of the Bilateral Segmentation Network."
        
        
         />
    </a>
  
  
    <figcaption>
      <span class="img--caption">
        Figure 1. An overview of the Bilateral Segmentation Network.
        
      </span>
    </figcaption>
  
</figure>




<h3 id="spatial-path">Spatial path<a class="anchor" href="#spatial-path">#</a></h3>
<p>Spatial Pathは十分な空間の情報を得るために必要である。
3つの畳込み層 (stride=2) からなり、そのあとにbatch normalization, ReLUが続く。
最終的に入力の1/8の特徴量マップが出力される。(上図 (a))</p>
<h3 id="context-path">Context path<a class="anchor" href="#context-path">#</a></h3>
<p>Context Pathは十分な受容野を得るために必要である。
pyramid poolingや大きなカーネルサイズを使うとメモリを消費し速度の低下につながるため使用しない。</p>
<p>Context Pathは軽量モデル (今回は pre-trained Xception) とglobal average poolingからなる。
軽量モデルでdownsampleを行い、global average poolingを行うことでglobalなcontextを捉えた需要野が得られる。
最終的にup-sampleされたglobal poolingの特徴量と軽量モデルの出力を組み合わせる。</p>
<p>ここで、ARM (Attention Refinement Module) はglobal average poolingを使ってglobalなcontextを得る。
そして、attentionベクトルを計算し、特徴量学習に使用する (上図 (b)) 。</p>
<h3 id="feature-fusion-module">Feature Fusion Module<a class="anchor" href="#feature-fusion-module">#</a></h3>
<p>それぞれのPathからの出力をまとめるモジュール。
Spatial Pathがローレベルの特徴を捉えているのに対し、Context Pathはハイレベルの特徴を捉えているため、そのまま足し合わせることはできない。
そこで、連結させたものに対してBatch Normalizationをかけ、SENetのように特徴ベクトルと重みベクトルを計算し、最終的な出力を導出する (上図 (c)) 。</p>
<h3 id="implementation">Implementation<a class="anchor" href="#implementation">#</a></h3>
<p>論文紹介はここまでで、実装を見ていきます。
pytorchによる実装は<a href="https://github.com/CoinCheung/BiSeNet/blob/master/lib/models/bisenetv1.py" 
  
   target="_blank" rel="noreferrer noopener" 
>こちら</a>
が分かりやすかったです。
下のコードのように、cp (context path) と sp (spatial path) から出力させた特徴量をffm (feature fusion module) で結合し、conv_out (畳み込み層x2+Upsampling) に入力することで、最終的な特徴量を得ています。</p>
<pre><code class="language-python">class BiSeNetV1(nn.Module):
    ...
    def forward(self, x):
        H, W = x.size()[2:]
        feat_cp8, feat_cp16 = self.cp(x)
        feat_sp = self.sp(x)
        feat_fuse = self.ffm(feat_sp, feat_cp8)
        feat_out = self.conv_out(feat_fuse)
</code></pre>
<h3 id="experiment">Experiment<a class="anchor" href="#experiment">#</a></h3>
<p>このBiSeNetを顔のパーツに応用 (修正) した<a href="https://github.com/zllrunning/face-parsing.PyTorch" 
  
   target="_blank" rel="noreferrer noopener" 
>こちら</a>
のライブラリを使ってその効果を確かめます。
<a href="https://github.com/switchablenorms/CelebAMask-HQ" 
  
   target="_blank" rel="noreferrer noopener" 
>CelebAMask-HQ</a>
で訓練されていて、19個のパーツに顔を分類することができます。</p>

  





<figure
  
  
  
  style='margin:0 auto;text-align:center;'
  >
    <a 
      
        data-lightbox="image-images/experiment.jpg"
      
      
        href="http://localhost:1313/blog/paper/bisenet/images/experiment.jpg"
      
    
    >
  <img
      
        src="http://localhost:1313/blog/paper/bisenet/images/experiment.jpg"
      
        alt="(Left) input image. (Right) output image."
        
        
         />
    </a>
  
  
    <figcaption>
      <span class="img--caption">
        Figure 2. (Left) input image. (Right) output image.
        
      </span>
    </figcaption>
  
</figure>




<p>出力を見ると目、鼻、口、髪など多くのパーツに正しく分けられていることが分かります。</p>
<h2 id="references">References<a class="anchor" href="#references">#</a></h2>
<ul>
<li>
<p>arXiv<br>
<a href="https://arxiv.org/abs/1808.00897" 
  
   target="_blank" rel="noreferrer noopener" 
>https://arxiv.org/abs/1808.00897</a>
</p>
</li>
<li>
<p>Github<br>
<a href="https://github.com/CoinCheung/BiSeNet" 
  
   target="_blank" rel="noreferrer noopener" 
>https://github.com/CoinCheung/BiSeNet</a>
</p>
</li>
</ul>


              
          </article>
          

<ul class="tags__list">
    
    <li class="tag__item">
        <a class="tag__link" href="http://localhost:1313/tags/segmentation/">segmentation</a>
    </li>
    <li class="tag__item">
        <a class="tag__link" href="http://localhost:1313/tags/paper/">paper</a>
    </li></ul>

 <div class="pagination">
  
    <a class="pagination__item" href="http://localhost:1313/blog/paper/deeplagrangianfluids/">
        <span class="pagination__label">Previous Post</span>
        <span class="pagination__title">Lagrangian Fluid Simulation With Continuous Convolutions を読む</span>
    </a>
  

  
    <a class="pagination__item" href="http://localhost:1313/blog/personal/desktop-20231201/">
      <span class="pagination__label">Next Post</span>
      <span class="pagination__title" >新しいPCを組んだので構成など</span>
    </a>
  
</div>

          
          <footer class="post__footer">
            


<div class="social-icons">
  
     
    
      <a class="social-icons__link" rel="me" title="Kaggle"
         href="https://www.kaggle.com/tsumli"
         target="_blank" rel="noopener">
        <div class="social-icons__icon" style="background-image: url('http://localhost:1313/svg/kaggle.svg')"></div>
      </a>
    
  
     
    
      <a class="social-icons__link" rel="me" title="GitHub"
         href="https://github.com/tsumli"
         target="_blank" rel="noopener">
        <div class="social-icons__icon" style="background-image: url('http://localhost:1313/svg/github.svg')"></div>
      </a>
    
     
</div>

            <p>© 2025</p>
            <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
            <link rel="stylesheet" href="http://localhost:1313//css/lightbox.min.css">
            <script src="http://localhost:1313//js/lightbox.min.js"></script>
          </footer>
          </div>
      </div>
      
      <div class="toc-container">
           <div class="toc-post-title">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation を読む</div> 
        <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#method">Method</a>
      <ul>
        <li><a href="#spatial-path">Spatial path</a></li>
        <li><a href="#context-path">Context path</a></li>
        <li><a href="#feature-fusion-module">Feature Fusion Module</a></li>
        <li><a href="#implementation">Implementation</a></li>
        <li><a href="#experiment">Experiment</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
      </div>
      
    </div>
    

  </main>

   

  
  <script src="http://localhost:1313/js/index.min.301a8b0870381bf76b3b5182e8966d363a0474281183439beb024d8b8228fc66.js" integrity="sha256-MBqLCHA4G/drO1GC6JZtNjoEdCgRg0Ob6wJNi4Io/GY=" crossorigin="anonymous"></script>
  
  
  <script src="https://unpkg.com/prismjs@1.20.0/components/prism-core.min.js"></script>

  
  <script src="https://unpkg.com/prismjs@1.20.0/plugins/autoloader/prism-autoloader.min.js"
    data-autoloader-path="https://unpkg.com/prismjs@1.20.0/components/"></script>

  
    <script src="http://localhost:1313/js/table-of-contents.js"></script>
  


</body>

</html>
