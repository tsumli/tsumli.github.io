<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>paper on tsumli-pages</title><link>https://tsumli.github.io/tags/paper/</link><description>Recent content in paper on tsumli-pages</description><generator>Hugo -- gohugo.io</generator><language>ja</language><copyright>© {year}</copyright><lastBuildDate>Fri, 08 Jul 2022 15:55:54 +0000</lastBuildDate><atom:link href="https://tsumli.github.io/tags/paper/index.xml" rel="self" type="application/rss+xml"/><item><title>Lagrangian Fluid Simulation With Continuous Convolutions を読む</title><link>https://tsumli.github.io/blog/paper/deeplagrangianfluids/</link><pubDate>Fri, 08 Jul 2022 15:55:54 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/deeplagrangianfluids/</guid><description>Lagrangian Fluid Simulation With Continuous Convolutions という論文を読んでいきます (本文中の図は論文より引用) 。 この論文では液体をグラフとして扱う&amp;hellip;のではなくspatia</description></item><item><title>First Order Motion Model for Image Animation (FOMM) を読む</title><link>https://tsumli.github.io/blog/paper/fomm/</link><pubDate>Tue, 01 Feb 2022 19:58:16 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/fomm/</guid><description>First Order Motion Model for Image Animation [A. Siarohin et al. NeurIPS 2019] という論文を読んでいきます (本文中の図は論文より引用)。 FOMMという名前で知られている手法です。 Figure . example animation Method 目的 source</description></item><item><title>Video Swin Transformer を読む</title><link>https://tsumli.github.io/blog/paper/video-swin-transformer/</link><pubDate>Thu, 14 Oct 2021 15:55:54 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/video-swin-transformer/</guid><description>Video Swin Transformer という論文を読んでいきます (本文中の図は論文より引用) 。ざっくり言うと、Swin Transformerをそのままvideoの入力に拡張</description></item><item><title>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows を読む</title><link>https://tsumli.github.io/blog/paper/swin-transformer/</link><pubDate>Thu, 14 Oct 2021 13:55:54 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/swin-transformer/</guid><description>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows という論文を読んでいきます (本文中の図は論文より引用) 。 Method Figure 1. The architecture of a Swin Transformer (b) two successive Swin Transformer Blocks. Swin Transformerの全体像 (小さ</description></item><item><title>One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing を読む</title><link>https://tsumli.github.io/blog/paper/one-shot-talking-head/</link><pubDate>Wed, 13 Oct 2021 13:55:54 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/one-shot-talking-head/</guid><description>One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing という論文を読んでいきます。CVPR 2021にacceptされています (本文中の図は論文より引用) 。 Figure . 提案手法の結果。H.</description></item><item><title>TGAN: Synthesizing Tabular Data using Generative Adversarial Networks を読む</title><link>https://tsumli.github.io/blog/paper/TGAN/</link><pubDate>Mon, 14 Jun 2021 10:33:39 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/TGAN/</guid><description>Synthesizing Tabular Data using Generative Adversarial Networks [Xu et al. arXiv 2018] という論文を読んでいきます. (本文中の図は論文より引用). tabular dataに対するGAN (TGAN) についての紹介. 様々なデータ (categorical, n</description></item><item><title>FNet: Mixing Tokens with Fourier Transforms を読む</title><link>https://tsumli.github.io/blog/paper/FNet/</link><pubDate>Thu, 03 Jun 2021 07:11:44 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/FNet/</guid><description>FNet: Mixing Tokens with Fourier Transforms [Thorp et al. arXiv 2020] という論文を読んでいきます. (本文中の図は論文より引用). Contributions: token &amp;ldquo;mixing&amp;rdquo; 変換がテキストデータにおける多様なsemanticsを</description></item><item><title>GANimation を読む</title><link>https://tsumli.github.io/blog/paper/GANimation/</link><pubDate>Sat, 22 May 2021 11:38:22 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/GANimation/</guid><description>$$ \def\image#1{\mathbf{I}_{\mathbf{y}{\scriptsize{#1}}}} $$ GANimation: Anatomically-aware Facial Animation from a Single Image [Pumarola et al. ECCV 2018] という論文を読んでいきます. (本文中の図は論文より引用). Action Units (AU) アノテーションに基づいたGAN Figure . Facial animation from a single</description></item><item><title>StarGAN v2 を読む</title><link>https://tsumli.github.io/blog/paper/StarGANv2/</link><pubDate>Fri, 21 May 2021 19:58:16 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/StarGANv2/</guid><description>StarGAN v2: Diverse Image Synthesis for Multiple Domains [Choi et al. CVPR 2020] という論文を読んでいきます. (本文中の図は論文より引用). Figure . Synthesis Result image-to-image translationのタスクにおいて, 異なる</description></item><item><title>Taskonomyを読む</title><link>https://tsumli.github.io/blog/paper/taskonomy/</link><pubDate>Mon, 01 Feb 2021 13:55:54 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/taskonomy/</guid><description>Taskonomy: Disentangling Task Transfer Learning という論文を読んでいきます。 この論文はCVPR 2018のBestPaperを受賞しています (本文中の図は論文より引用) 。 Motivation タスク間</description></item></channel></rss>