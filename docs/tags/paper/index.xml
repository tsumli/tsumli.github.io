<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>paper on tsumli-pages</title><link>https://tsumli.github.io/tags/paper/</link><description>Recent content in paper on tsumli-pages</description><generator>Hugo -- gohugo.io</generator><language>ja</language><copyright>© {year}</copyright><lastBuildDate>Sat, 22 May 2021 11:38:22 +0000</lastBuildDate><atom:link href="https://tsumli.github.io/tags/paper/index.xml" rel="self" type="application/rss+xml"/><item><title>GANimation を読む</title><link>https://tsumli.github.io/blog/paper/GANimation/</link><pubDate>Sat, 22 May 2021 11:38:22 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/GANimation/</guid><description>$$ \def\image#1{\mathbf{I}_{\mathbf{y}{\scriptsize{#1}}}} $$ GANimation: Anatomically-aware Facial Animation from a Single Image [Pumarola et al. ECCV 2018] という論文を読んでいきます. (本文中の図は論文より引用). Action Units (AU) アノテーションに基づいたGAN Figure . Facial animation from a single</description></item><item><title>StarGAN v2 を読む</title><link>https://tsumli.github.io/blog/paper/StarGANv2/</link><pubDate>Fri, 21 May 2021 19:58:16 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/StarGANv2/</guid><description>StarGAN v2: Diverse Image Synthesis for Multiple Domains [Choi et al. CVPR 2020] という論文を読んでいきます. (本文中の図は論文より引用). Figure . Synthesis Result image-to-image translationのタスクにおいて, 異なる</description></item><item><title>Taskonomyを読む</title><link>https://tsumli.github.io/blog/paper/taskonomy/</link><pubDate>Mon, 01 Feb 2021 13:55:54 +0000</pubDate><guid>https://tsumli.github.io/blog/paper/taskonomy/</guid><description>Taskonomy: Disentangling Task Transfer Learning という論文を読んでいきます。 この論文はCVPR 2018のBestPaperを受賞しています (本文中の図は論文より引用) 。 Motivation タスク間</description></item></channel></rss>